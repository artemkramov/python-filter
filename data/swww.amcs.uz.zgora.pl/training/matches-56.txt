4 - December 2000
10 - 2000
Neural networks in the framework of granular computing
Witold Pedrycz
The study is concerned with the fundamentals of granular computing and its application to neural networks. Granular computing, as the name itself stipulates, deals with representing information in the form of some aggregates (embracing a number of individual entitites) and their ensuing processing. We elaborate on the rationale behind granular computing. Next, a number of formal frameworks of information granulation are discussed including several alternatives such as fuzzy sets, interval analysis, rough sets, and probability. The notion of granularity itself is defined and quantified. A design agenda of granular computing is formulated and the key design problems are raised. A number of granular architectures are also discussed with an objective of dealineating the fundamental algorithmic and conceptual challenges. It is shown that the use of information granules of different size (granularity) lends itself to general pyramid architectures of information processing. The role of encoding and decoding mechanisms visible in this setting is also discussed in detail along with some particular solutions. Neural networks are primarily involved at the level of numeric optimization. Granularity of information introduces another dimension to the neurocomputing. We discuss the role of granular constructs in the design of neural networks and knowledge representation therein. The intent of this paper is to elaborate on the fundamentals and put the entire area in a certain perspective while not moving into specific algorithmic details.
information granulation, pyramid architectures, encoding and decoding, neural networks, learning, knowledge representation
