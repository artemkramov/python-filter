1 - March 2014
24 - 2014
A differential evolution approach to dimensionality reduction for classification needs
Goran Martinović, Dražen Bajer, Bruno Zorić
The feature selection problem often occurs in pattern recognition and, more specifically, classification. Although these patterns could contain a large number of features, some of them could prove to be irrelevant, redundant or even detrimental to classification accuracy. Thus, it is important to remove these kinds of features, which in turn leads to problem dimensionality reduction and could eventually improve the classification accuracy. In this paper an approach to dimensionality reduction based on differential evolution which represents a wrapper and explores the solution space is presented. The solutions, subsets of the whole feature set, are evaluated using the<em>k</em>-nearest neighbour algorithm. High quality solutions found during execution of the differential evolution fill the archive. A final solution is obtained by conducting<em>k</em>-fold cross-validation on the archive solutions and selecting the best one. Experimental analysis is conducted on several standard test sets. The classification accuracy of the<em>k</em>-nearest neighbour algorithm using the full feature set and the accuracy of the same algorithm using only the subset provided by the proposed approach and some other optimization algorithms which were used as wrappers are compared. The analysis shows that the proposed approach successfully determines good feature subsets which may increase the classification accuracy.
classification, differential evolution, feature subset selection,<em>k</em>-nearest neighbour algorithm, wrapper method</p><p><strong>DOI</strong><br><a href="http://dx.doi.org/10.2478/amcs-2014-0009">10.2478/amcs-2014-0009</a>
